{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47633113",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import os\n",
    "\n",
    "batch_size=32\n",
    "img_height=64\n",
    "img_width=64\n",
    "\n",
    "base_dir = os.path.join(os.getcwd())\n",
    "train_dir = os.path.join(base_dir, 'asl_alphabet_train/asl_alphabet_train')\n",
    "\n",
    "print(base_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "839799fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "    train_dir,\n",
    "    validation_split=0.1,\n",
    "    subset=\"training\",\n",
    "    seed=123,\n",
    "    image_size=(img_height, img_width),\n",
    "    batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90af0e4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "    train_dir,\n",
    "    validation_split=0.20,\n",
    "    subset=\"validation\",\n",
    "    seed=123,\n",
    "    image_size=(img_height, img_width),\n",
    "    batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb072a72",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "    train_dir,\n",
    "    validation_split=0.8,\n",
    "    subset=\"validation\",\n",
    "    seed=123,\n",
    "    image_size=(img_height, img_width),\n",
    "    batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b58a8047",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "class_names = train_ds.class_names\n",
    "plt.figure(figsize=(10, 10))\n",
    "for images, labels in train_ds.take(1):\n",
    "    for i in range(len(class_names)):\n",
    "        ax = plt.subplot(6,5 , i + 1)\n",
    "        plt.imshow(images[i].numpy().astype(\"uint8\"))\n",
    "        plt.title(class_names[labels[i]])\n",
    "        plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58c772f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import Sequential\n",
    "from keras import layers\n",
    "\n",
    "model = Sequential([\n",
    "    layers.Rescaling(1./255),\n",
    "    layers.Conv2D(16, 3, padding='same', activation='relu'),\n",
    "    layers.MaxPooling2D(),\n",
    "\n",
    "    layers.Conv2D(32, 3, padding='same', activation='relu'),\n",
    "    layers.MaxPooling2D(),\n",
    "    layers.Dropout(0.25),\n",
    "\n",
    "    layers.Conv2D(64, 3, padding='same', activation='relu'),\n",
    "    layers.MaxPooling2D(),\n",
    "    layers.Dropout(0.25),\n",
    "    \n",
    "    layers.Conv2D(128, 3, padding='same', activation='relu'),\n",
    "    layers.MaxPooling2D(),\n",
    "    layers.Dropout(0.25),\n",
    "\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(256, activation='relu'),\n",
    "    layers.Dense(len(class_names), activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29beb7c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='sparse_categorical_crossentropy',optimizer='adam',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51382b42",
   "metadata": {},
   "outputs": [],
   "source": [
    "device_name = tf.test.gpu_device_name()\n",
    "if \"GPU\" not in device_name:\n",
    "    history = model.fit(train_ds, batch_size=32,validation_batch_size=32, validation_data=validation_ds,epochs=10)\n",
    "else: \n",
    "    with tf.device('/device:GPU:0'):\n",
    "        history = model.fit(train_ds, batch_size=32,validation_batch_size=32, validation_data=validation_ds,epochs=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa8a24b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs = range(len(acc))\n",
    "\n",
    "plt.plot(epochs, acc, 'r', label='Training accuracy')\n",
    "plt.plot(epochs, val_acc, 'b', label='Validation accuracy')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.legend()\n",
    "plt.figure()\n",
    "\n",
    "plt.plot(epochs, loss, 'r', label='Training Loss')\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation Loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b7b987e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('model1.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c18b3dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "actual = []\n",
    "pred = []\n",
    "for images, labels in test_ds:\n",
    "    for i in range(0, len(images)):\n",
    "        image = images[i]\n",
    "        image = np.expand_dims(image, axis=0)\n",
    "        result = model.predict(image)\n",
    "        pred.append(class_names[np.argmax(result)])\n",
    "        actual.append(class_names[labels[i].numpy()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40d5af6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "\n",
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \n",
    "    plt.figure(figsize=(15, 15))\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, cm[i, j],\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79c4a1b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "cm = confusion_matrix(y_true=actual, y_pred=pred)\n",
    "plot_confusion_matrix(cm=cm, classes=class_names, title='Confusion Matrix')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73fb984f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from keras.preprocessing import image\n",
    "\n",
    "# actual = []\n",
    "# pred = []\n",
    "# base_dir = os.getcwd()\n",
    "# directories = os.listdir(base_dir + '\\..\\input\\asl-alphabet-test\\\\')\n",
    "# for directory in directories:\n",
    "#     if directory == 'asl-alphabet-test': continue\n",
    "#     images = os.listdir(base_dir + '\\..\\input\\asl-alphabet-test\\' + directory')\n",
    "#     dirl= '\\..\\input\\asl-alphabet-test\\' + directory + \"\\\"\n",
    "#     for image in dirl:\n",
    "#         test_image = image.load_img(base_dir + '\\..\\input\\asl-alphabet-test\\' + directory + \"\\\" + images[i], target_size=(img_width, img_height))\n",
    "#         test_image = image.img_to_array(test_image)\n",
    "#         test_image = np.expand_dims(test_image, axis=0)\n",
    "#         result = model.predict(test_image)\n",
    "#         pred.append(class_names[np.argmax(result)])\n",
    "#         actual.append(directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d2fc273",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(y_true=actual, y_pred=pred)\n",
    "plot_confusion_matrix(cm=cm, classes=class_names, title='Confusion Matrix')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7c1e6c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from tensorflow.keras.utils import load_img, img_to_array \n",
    "from keras.models import load_model\n",
    "import PIL\n",
    "\n",
    "img = load_img(\"/content/asl_alphabet_test/asl_alphabet_test/E_test.jpg\")\n",
    "img = img.resize((img_width, img_height))\n",
    "img = img_to_array(img) \n",
    "\n",
    "img = img.reshape( -1,img_width, img_height,3)\n",
    "\n",
    "print(img.shape)\n",
    "model = load_model('model1.h5')\n",
    "model.summary()\n",
    "abc = model.predict(img)\n",
    "\n",
    "print(abc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5aa6fc2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
