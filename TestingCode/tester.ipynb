{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3a531016",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['A', 'B', 'C', 'D', 'E']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 5/5 [00:18<00:00,  3.67s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " rescaling (Rescaling)       (None, 96, 96, 3)         0         \n",
      "                                                                 \n",
      " conv2d (Conv2D)             (None, 96, 96, 16)        448       \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 48, 48, 16)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 48, 48, 32)        4640      \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 24, 24, 32)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 24, 24, 32)        0         \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 24, 24, 64)        18496     \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 12, 12, 64)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 12, 12, 64)        0         \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 12, 12, 128)       73856     \n",
      "                                                                 \n",
      " max_pooling2d_3 (MaxPooling  (None, 6, 6, 128)        0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 6, 6, 128)         0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 4608)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 256)               1179904   \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 257       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,277,601\n",
      "Trainable params: 1,277,601\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/5\n",
      "67/67 [==============================] - 8s 103ms/step - loss: 1.3878 - mae: 1.3878 - val_loss: 1.4693 - val_mae: 1.4693 - lr: 0.0010\n",
      "Epoch 2/5\n",
      "67/67 [==============================] - 7s 98ms/step - loss: 1.3878 - mae: 1.3878 - val_loss: 1.4693 - val_mae: 1.4693 - lr: 0.0010\n",
      "Epoch 3/5\n",
      "67/67 [==============================] - 7s 100ms/step - loss: 1.3878 - mae: 1.3878 - val_loss: 1.4693 - val_mae: 1.4693 - lr: 0.0010\n",
      "Epoch 4/5\n",
      "67/67 [==============================] - 7s 100ms/step - loss: 1.3878 - mae: 1.3878 - val_loss: 1.4693 - val_mae: 1.4693 - lr: 0.0010\n",
      "Epoch 5/5\n",
      "67/67 [==============================] - 7s 101ms/step - loss: 1.3878 - mae: 1.3878 - val_loss: 1.4693 - val_mae: 1.4693 - lr: 0.0010\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 4 of 4). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\DELVIN\\AppData\\Local\\Temp\\tmpg0tqxd_4\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\DELVIN\\AppData\\Local\\Temp\\tmpg0tqxd_4\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/12 [==============================] - 0s 22ms/step\n",
      "[[1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]]\n",
      "[1. 1. 2. 1. 4. 0. 1. 0. 0. 1. 1. 2. 1. 1. 4. 0. 3. 3. 3. 2. 0. 1. 2. 0.\n",
      " 3. 4. 0. 1. 4. 4. 3. 2. 4. 1. 3. 2. 2. 4. 2. 1. 3. 4. 4. 4. 2. 4. 1. 0.\n",
      " 2. 0. 2. 4. 0. 3. 1. 2. 1. 1. 4. 3. 3. 0. 4. 3. 4. 3. 0. 0. 3. 3. 2. 3.\n",
      " 1. 0. 3. 3. 2. 0. 2. 4. 0. 2. 4. 4. 0. 2. 2. 0. 0. 0. 1. 3. 0. 2. 0. 0.\n",
      " 1. 2. 1. 0. 2. 0. 3. 4. 0. 0. 4. 2. 1. 4. 4. 1. 0. 2. 4. 1. 3. 3. 2. 4.\n",
      " 2. 1. 2. 2. 0. 4. 4. 3. 4. 2. 0. 2. 3. 2. 4. 3. 3. 2. 0. 2. 4. 3. 4. 3.\n",
      " 1. 0. 1. 0. 1. 3. 4. 4. 4. 2. 3. 1. 3. 2. 4. 0. 2. 3. 1. 3. 2. 2. 1. 1.\n",
      " 3. 4. 4. 0. 4. 0. 4. 2. 3. 3. 4. 1. 3. 3. 3. 3. 2. 4. 3. 0. 3. 0. 3. 3.\n",
      " 1. 2. 1. 3. 3. 1. 3. 0. 2. 0. 2. 0. 4. 4. 1. 2. 1. 2. 0. 4. 2. 2. 3. 4.\n",
      " 3. 3. 0. 3. 2. 0. 0. 2. 3. 1. 2. 4. 0. 0. 4. 0. 4. 0. 1. 1. 3. 0. 2. 4.\n",
      " 3. 1. 2. 1. 4. 2. 1. 2. 1. 1. 2. 0. 1. 2. 1. 0. 0. 0. 4. 4. 3. 0. 4. 4.\n",
      " 4. 1. 1. 0. 3. 2. 1. 0. 1. 4. 2. 2. 2. 4. 2. 3. 1. 4. 3. 0. 0. 1. 4. 4.\n",
      " 3. 3. 0. 3. 4. 4. 4. 0. 3. 4. 1. 3. 0. 4. 3. 3. 3. 2. 1. 1. 0. 4. 3. 2.\n",
      " 0. 2. 3. 1. 0. 4. 1. 4. 2. 3. 3. 4. 1. 1. 4. 2. 2. 3. 2. 4. 4. 2. 0. 4.\n",
      " 3. 1. 3. 3. 1. 4. 3. 4. 1. 4. 2. 0. 4. 1. 3. 1. 4. 3. 1. 4. 2. 4. 4. 3.\n",
      " 1. 3. 1. 1. 4. 3. 1. 3. 1. 0. 3. 3. 4. 2. 3.]\n"
     ]
    }
   ],
   "source": [
    "# import all required labraries\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import os\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "\n",
    "# save and run\n",
    "\n",
    "# now define path to dataset\n",
    "path=\"asl_alphabet_train/asl_alphabet_train\"\n",
    "files=os.listdir(path)\n",
    "# list of files in path\n",
    "# sort path from A-Y\n",
    "files.sort()\n",
    "\n",
    "# print to see list\n",
    "print(files)\n",
    "\n",
    "\n",
    "# create list of image and label\n",
    "\n",
    "image_array=[]\n",
    "label_array=[]\n",
    "# loop through each file in files\n",
    "\n",
    "for i in tqdm(range(len(files))):\n",
    "\t# list of image in each folder\n",
    "\tsub_file=os.listdir(path+\"/\"+files[i])\n",
    "\t# let's check length of each folder\n",
    "\t#\tprint(len(sub_file))\n",
    "\n",
    "\t# loop through each sub folder\n",
    "\tfor j in range(len(sub_file)):\n",
    "\n",
    "\t\t# path of each image\n",
    "\t\t#Example:imagepro/A/image_name1.jpg\n",
    "\n",
    "\t\tfile_path=path+\"/\"+files[i]+\"/\"+sub_file[j]\n",
    "\t\t# read each image\n",
    "\n",
    "\t\timage=cv2.imread(file_path)\n",
    "\n",
    "\t\t# resize image by 96x96\n",
    "\t\timage=cv2.resize(image,(96,96))\n",
    "\t\t# convert BGR image to RGB image\n",
    "\t\timage=cv2.cvtColor(image,cv2.COLOR_BGR2RGB)\n",
    "\n",
    "\t\t# add this image at image_array\n",
    "\t\timage_array.append(image)\n",
    "\n",
    "\t\t# add label to label_array\n",
    "\t\t# i is number from 0 to len(files)-1\n",
    "\t\t# so we can use it as label\n",
    "\t\tlabel_array.append(i)\n",
    "\n",
    "# save and run to see if it is working or not\n",
    "# before that apply tqdm to for loop\n",
    "# it is working with no errors\n",
    "\n",
    "# convert list to array\n",
    "\n",
    "image_array=np.array(image_array)\n",
    "label_array=np.array(label_array,dtype=\"float\")\n",
    "\n",
    "# split the dataset into test and train\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "# output\t\t\t\t\t\t\t\t\t   train image   label      spliting size\n",
    "X_train,X_test,Y_train,Y_test=train_test_split(image_array,label_array,test_size=0.15)\n",
    "\n",
    "del image_array,label_array\n",
    "\n",
    "# to free memory \n",
    "import gc\n",
    "gc.collect()\n",
    "\n",
    "\n",
    "# X_train will have 85% of images \n",
    "# X_test will have 15% of images\n",
    "\n",
    "\n",
    "# Create a model\n",
    "\n",
    "from keras import layers,callbacks,utils,applications,optimizers\n",
    "from keras.models import Sequential, Model, load_model\n",
    "\n",
    "model=Sequential()\n",
    "# add pretrained models to Sequential model\n",
    "# I will use EfficientNetB0 pretrained model. You can try different model.\n",
    "pretrained_model=tf.keras.applications.EfficientNetB0(input_shape=(96,96,3),include_top=False)\n",
    "model.add(pretrained_model)\n",
    "\n",
    "# add Pooling to model\n",
    "model.add(layers.GlobalAveragePooling2D())\n",
    "\n",
    "# add dropout to model\n",
    "# We add dropout to increase accuracy by reduce overfitting\n",
    "model.add(layers.Dropout(0.3))\n",
    "# finally we will addd dense layer as an output\n",
    "model.add(layers.Dense(1))\n",
    "# For some tensorflow version we required to build model\n",
    "model.build(input_shape=(None,96,96,3))\n",
    "\n",
    "\n",
    "# to see model summary\n",
    "model.summary()\n",
    "\n",
    "\n",
    "# save and run to see model summary \n",
    "# make sure your pc is connected to internet to download pretrained weight\n",
    "# It will take some time\n",
    "# Everything till now works\n",
    "# I am using GPU to train model so it will take 20-30 min.\n",
    "# If you train model on CPU it will take some time\n",
    "\n",
    "\n",
    "# compile model\n",
    "# you can use different optimizer and loss function to increase accuracy\n",
    "model.compile(optimizer=\"adam\",loss=\"mae\",metrics=[\"mae\"])\n",
    "\n",
    "# create a checkpoint to save best accuracy model\n",
    "ckp_path=\"trained_model/model\"\n",
    "model_checkpoint=tf.keras.callbacks.ModelCheckpoint(\n",
    "\t\t\t\t\t\t\t\t\tfilepath=ckp_path,\n",
    "\t\t\t\t\t\t\t\t\tmonitor=\"val_mae\",\n",
    "\t\t\t\t\t\t\t\t\tmode=\"auto\",\n",
    "\t\t\t\t\t\t\t\t\tsave_best_only=True,\n",
    "\t\t\t\t\t\t\t\t\tsave_weights_only=True\n",
    "\t\t\t\t\t\t\t\t\t)\n",
    "# monitor: monitor validation mae loss to save model\n",
    "# mode: Use to save model when val_mae is minimum or maximum\n",
    "# It has 3 option: \"min\",\"max\",\"auto\".\n",
    "# for us you can select either \"min\" or \"auto\"\n",
    "# When val_mae reduce model will be saved\n",
    "# save_best_only: False -> It will save all model\n",
    "# save_weights_only: Save only weight.\n",
    "\n",
    "\n",
    "# create learning rate reducer to reduce lr when accuracy does not improve\n",
    "# Correct \n",
    "reduce_lr=tf.keras.callbacks.ReduceLROnPlateau(\n",
    "\t\t\t\t\t\t\t\t\tfactor=0.9,\n",
    "\t\t\t\t\t\t\t\t\tmonitor=\"val_mae\",\n",
    "\t\t\t\t\t\t\t\t\tmode=\"auto\",\n",
    "\t\t\t\t\t\t\t\t\tcooldown=0,\n",
    "\t\t\t\t\t\t\t\t\tpatience=5,\n",
    "\t\t\t\t\t\t\t\t\tverbose=1,\n",
    "\t\t\t\t\t\t\t\t\tmin_lr=1e-6)\n",
    "\n",
    "# factor: when it is reduce next lr will be 0.9 times of current\n",
    "# next lr= 0.9* current lr\n",
    "\n",
    "# patience=X\n",
    "# reduce lr after X epoch when accuracy does not improve\n",
    "# verbose : show it after every epoch\n",
    "\n",
    "# min_lr : minimum learning rate \n",
    "\n",
    "# Start training model\n",
    "\n",
    "Epochs=5\n",
    "Batch_Size=32\n",
    "# Select batch size according to your Graphic card \n",
    "#\n",
    "#X_train,X_test,Y_train,Y_test\n",
    "with tf.device('/device:GPU:0'):\n",
    "\thistory=model.fit(\n",
    "\t\t\t\t\tX_train,\n",
    "\t\t\t\t\tY_train,\n",
    "\t\t\t\t\tvalidation_data=(X_test,Y_test),\n",
    "\t\t\t\t\tbatch_size=Batch_Size,\n",
    "\t\t\t\t\tepochs=Epochs,\n",
    "\t\t\t\t\tcallbacks=[model_checkpoint,reduce_lr]\n",
    "\t\t\t\t\t)\n",
    "# Before training you can delete image_array and label_array to increase ram memory \n",
    "\n",
    "# Some error correction\n",
    "# This code will be in the description so you can cross check everything\n",
    "# Save and run \n",
    "# Everything is working\n",
    "\n",
    "# after the training is done load best model\n",
    "\n",
    "model.load_weights(ckp_path)\n",
    "\n",
    "# convert model to tensorflow lite model\n",
    "\n",
    "converter=tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "tflite_model=converter.convert()\n",
    "\n",
    "# save model\n",
    "with open(\"model.tflite\",\"wb\") as f:\n",
    "\tf.write(tflite_model)\n",
    "\n",
    "# if you want to see prediction result on test dataset\n",
    "prediction_val=model.predict(X_test,batch_size=32)\n",
    "\n",
    "# print first 10 values\n",
    "print(prediction_val)\n",
    "# print first 10 values of Y_test\n",
    "print(Y_test)\n",
    "\n",
    "# Save and run this python file\n",
    "# Before that I will show you\n",
    "# loss: 0.4074 - mae: 0.4074 - val_loss: 0.3797 - val_mae: 0.3797\n",
    "# we have mae and val_mae:\n",
    "# mae: Is on X_train\n",
    "# val_mae: X_test\n",
    "# If val_mae is reducing that means your model is improving.\n",
    "\n",
    "# I will show you the result after the training is over\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d2e58205",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['E_test.jpg']\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "[[1.]]\n",
      "[0.]\n",
      "['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z']\n",
      "[1.]  Pred= = B\n"
     ]
    }
   ],
   "source": [
    "# now define path to dataset\n",
    "path=\"DownloadedSamples\"\n",
    "files=os.listdir(path)\n",
    "# list of files in path\n",
    "# sort path from A-Y\n",
    "files.sort()\n",
    "\n",
    "# print to see list\n",
    "print(files)\n",
    "\n",
    "\n",
    "# create list of image and label\n",
    "\n",
    "image_array=[]\n",
    "label_array=[]\n",
    "# loop through each file in files\n",
    "\n",
    "#for i in tqdm(range(len(files))):\n",
    "\t# list of image in each folder\n",
    "\t#sub_file=os.listdir(path+\"/\"+files[i])\n",
    "\t# let's check length of each folder\n",
    "\t#\tprint(len(sub_file))\n",
    "\n",
    "i=0\n",
    "# loop through each sub folder\n",
    "for j in range(len(files)):\n",
    "\n",
    "    # path of each image\n",
    "    #Example:imagepro/A/image_name1.jpg\n",
    "\n",
    "    file_path=path+\"/\"+files[j]\n",
    "    # read each image\n",
    "\n",
    "    image=cv2.imread(file_path)\n",
    "\n",
    "    # resize image by 96x96\n",
    "    image=cv2.resize(image,(96,96))\n",
    "    # convert BGR image to RGB image\n",
    "    image=cv2.cvtColor(image,cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    # add this image at image_array\n",
    "    image_array.append(image)\n",
    "\n",
    "    # add label to label_array\n",
    "    # i is number from 0 to len(files)-1\n",
    "    # so we can use it as label\n",
    "    label_array.append(i)\n",
    "    i=i+1\n",
    "\n",
    "# save and run to see if it is working or not\n",
    "# before that apply tqdm to for loop\n",
    "# it is working with no errors\n",
    "\n",
    "# convert list to array\n",
    "\n",
    "image_array=np.array(image_array)\n",
    "label_array=np.array(label_array,dtype=\"float\")\n",
    "\n",
    "# if you want to see prediction result on test dataset\n",
    "prediction_val=model.predict(image_array,batch_size=32)\n",
    "\n",
    "# print first 10 values\n",
    "print(prediction_val)\n",
    "# print first 10 values of Y_test\n",
    "print(label_array)\n",
    "\n",
    "import string\n",
    "leter=()\n",
    "leter=list(string.ascii_uppercase)\n",
    "print(leter)\n",
    "\n",
    "j=0\n",
    "for i in range(len(files)):\n",
    "    \n",
    "    #print(prediction_val[i], \" Act=\", leter[i], \" Pred=\", end=\" \")\n",
    "    print(prediction_val[i], \" Pred=\", end=\" \")\n",
    "    \n",
    "    if prediction_val[i]>=-0.5 and prediction_val[i]<0.5:\n",
    "        print(\"= A\")\n",
    "    elif prediction_val[i]>=-0.5 and prediction_val[i]<1.5:\n",
    "        print(\"= B\")\n",
    "    elif prediction_val[i]>=-1.5 and prediction_val[i]<2.5:\n",
    "        print(\"= C\")\n",
    "    elif prediction_val[i]>=-2.5 and prediction_val[i]<3.5:\n",
    "        print(\"= D\")\n",
    "    elif prediction_val[i]>=-3.5 and prediction_val[i]<4.5:\n",
    "        print(\"= E\")\n",
    "    elif prediction_val[i]>=-4.5 and prediction_val[i]<5.5:\n",
    "        print(\"= F\")\n",
    "    elif prediction_val[i]>=-5.5 and prediction_val[i]<6.5:\n",
    "        print(\"= G\")\n",
    "    elif prediction_val[i]>=-6.5 and prediction_val[i]<7.5:\n",
    "        print(\"= H\")\n",
    "    elif prediction_val[i]>=-7.5 and prediction_val[i]<8.5:\n",
    "        print(\"= I\")\n",
    "    elif prediction_val[i]>=-8.5 and prediction_val[i]<9.5:\n",
    "        print(\"= J\")\n",
    "        \n",
    "    elif prediction_val[i]>=-9.5 and prediction_val[i]<10.5:\n",
    "        print(\"= K\")\n",
    "    elif prediction_val[i]>=-10.5 and prediction_val[i]<11.5:\n",
    "        print(\"= L\")\n",
    "    elif prediction_val[i]>=-11.5 and prediction_val[i]<12.5:\n",
    "        print(\"= M\")\n",
    "    elif prediction_val[i]>=-12.5 and prediction_val[i]<13.5:\n",
    "        print(\"= N\")\n",
    "    elif prediction_val[i]>=-13.5 and prediction_val[i]<14.5:\n",
    "        print(\"= O\")\n",
    "    elif prediction_val[i]>=-14.5 and prediction_val[i]<15.5:\n",
    "        print(\"= P\")\n",
    "    elif prediction_val[i]>=-15.5 and prediction_val[i]<16.5:\n",
    "        print(\"= Q\")\n",
    "    elif prediction_val[i]>=-16.5 and prediction_val[i]<17.5:\n",
    "        print(\"= R\")\n",
    "    elif prediction_val[i]>=-17.5 and prediction_val[i]<18.5:\n",
    "        print(\"= S\")\n",
    "    elif prediction_val[i]>=-18.5 and prediction_val[i]<19.5:\n",
    "        print(\"= T\")\n",
    "    \n",
    "    elif prediction_val[i]>=-19.5 and prediction_val[i]<20.5:\n",
    "        print(\"= U\")\n",
    "    elif prediction_val[i]>=-20.5 and prediction_val[i]<21.5:\n",
    "        print(\"= V\")\n",
    "    elif prediction_val[i]>=-21.5 and prediction_val[i]<22.5:\n",
    "        print(\"= W\")\n",
    "    elif prediction_val[i]>=-22.5 and prediction_val[i]<23.5:\n",
    "        print(\"= X\")\n",
    "    elif prediction_val[i]>=-23.5 and prediction_val[i]<24.5:\n",
    "        print(\"= Y\")\n",
    "    elif prediction_val[i]>=-24.5 and prediction_val[i]<25.5:\n",
    "        print(\"= Z\")\n",
    "    elif prediction_val[i]>=-25.5 and prediction_val[i]<26.5:\n",
    "        print(\"= DEL\")\n",
    "    elif prediction_val[i]>=-26.5 and prediction_val[i]<27.5:\n",
    "        print(\"= NOTHING\")\n",
    "    elif prediction_val[i]>=-27.5 and prediction_val[i]<28.5:\n",
    "        print(\"= SPACE\")\n",
    "    else:\n",
    "        print(\"= Dont Know!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9a798123",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Function `_wrapped_model` contains input name(s) mobilenet_1.00_224_input with unsupported characters which will be renamed to mobilenet_1_00_224_input in the SavedModel.\n",
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 27). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\DELVIN\\AppData\\Local\\Temp\\tmppkl7olue\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\DELVIN\\AppData\\Local\\Temp\\tmppkl7olue\\assets\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "#load the model to convert it.\n",
    "model = load_model('model2.h5')\n",
    "\n",
    "# Convert the model. from hd5 model to tflite. U sure about that?its directly from model\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS, tf.lite.OpsSet.SELECT_TF_OPS]\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "tflite_model = converter.convert()\n",
    "\n",
    "# Save the model.\n",
    "with open('model_h5.tflite', 'wb') as f:\n",
    "  f.write(tflite_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8f19bb5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
