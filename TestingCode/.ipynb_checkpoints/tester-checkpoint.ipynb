{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3a531016",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['A', 'B', 'C', 'D', 'E']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 5/5 [00:01<00:00,  3.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " rescaling_3 (Rescaling)     (None, 96, 96, 3)         0         \n",
      "                                                                 \n",
      " conv2d_12 (Conv2D)          (None, 96, 96, 16)        448       \n",
      "                                                                 \n",
      " max_pooling2d_12 (MaxPoolin  (None, 48, 48, 16)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_13 (Conv2D)          (None, 48, 48, 32)        4640      \n",
      "                                                                 \n",
      " max_pooling2d_13 (MaxPoolin  (None, 24, 24, 32)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dropout_9 (Dropout)         (None, 24, 24, 32)        0         \n",
      "                                                                 \n",
      " conv2d_14 (Conv2D)          (None, 24, 24, 64)        18496     \n",
      "                                                                 \n",
      " max_pooling2d_14 (MaxPoolin  (None, 12, 12, 64)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dropout_10 (Dropout)        (None, 12, 12, 64)        0         \n",
      "                                                                 \n",
      " conv2d_15 (Conv2D)          (None, 12, 12, 128)       73856     \n",
      "                                                                 \n",
      " max_pooling2d_15 (MaxPoolin  (None, 6, 6, 128)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dropout_11 (Dropout)        (None, 6, 6, 128)         0         \n",
      "                                                                 \n",
      " flatten_3 (Flatten)         (None, 4608)              0         \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 256)               1179904   \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 5)                 1285      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,278,629\n",
      "Trainable params: 1,278,629\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/5\n",
      "67/67 [==============================] - 8s 104ms/step - loss: 1.8567 - mae: 1.8567 - val_loss: 2.0123 - val_mae: 2.0123 - lr: 0.0010\n",
      "Epoch 2/5\n",
      "67/67 [==============================] - 7s 99ms/step - loss: 1.8567 - mae: 1.8567 - val_loss: 2.0123 - val_mae: 2.0123 - lr: 0.0010\n",
      "Epoch 3/5\n",
      "67/67 [==============================] - 7s 100ms/step - loss: 1.8567 - mae: 1.8567 - val_loss: 2.0123 - val_mae: 2.0123 - lr: 0.0010\n",
      "Epoch 4/5\n",
      "67/67 [==============================] - 7s 100ms/step - loss: 1.8567 - mae: 1.8567 - val_loss: 2.0123 - val_mae: 2.0123 - lr: 0.0010\n",
      "Epoch 5/5\n",
      "67/67 [==============================] - 7s 99ms/step - loss: 1.8567 - mae: 1.8567 - val_loss: 2.0123 - val_mae: 2.0123 - lr: 0.0010\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 4 of 4). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\DELVIN\\AppData\\Local\\Temp\\tmpdd6wcdy3\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\DELVIN\\AppData\\Local\\Temp\\tmpdd6wcdy3\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/12 [==============================] - 0s 21ms/step\n",
      "[[0.2169232  0.20323917 0.20552455 0.1830652  0.19124788]\n",
      " [0.20716299 0.20812541 0.20674711 0.18590598 0.1920585 ]\n",
      " [0.21004699 0.20066035 0.21333624 0.18585679 0.19009966]\n",
      " ...\n",
      " [0.21404064 0.20369163 0.20637798 0.18579285 0.19009687]\n",
      " [0.21696985 0.20046048 0.20436253 0.1862609  0.19194621]\n",
      " [0.21520688 0.2048352  0.20395674 0.18204643 0.19395478]]\n",
      "[2. 0. 0. 0. 3. 3. 1. 0. 2. 1. 3. 1. 1. 3. 4. 1. 3. 2. 4. 2. 3. 3. 1. 2.\n",
      " 4. 0. 4. 2. 2. 2. 4. 0. 0. 4. 4. 0. 0. 0. 3. 3. 1. 0. 3. 4. 3. 0. 3. 3.\n",
      " 4. 4. 1. 2. 0. 2. 2. 0. 0. 4. 4. 1. 3. 4. 0. 3. 2. 1. 3. 4. 3. 1. 3. 2.\n",
      " 1. 1. 3. 4. 0. 3. 3. 3. 1. 3. 4. 1. 1. 0. 4. 1. 0. 3. 3. 2. 4. 0. 4. 0.\n",
      " 1. 4. 3. 3. 3. 2. 3. 1. 3. 3. 2. 2. 3. 4. 4. 1. 2. 1. 0. 2. 0. 4. 4. 4.\n",
      " 3. 4. 4. 0. 4. 1. 4. 3. 1. 1. 2. 1. 1. 2. 2. 0. 2. 3. 3. 2. 4. 4. 2. 3.\n",
      " 0. 0. 3. 3. 3. 3. 4. 0. 4. 4. 3. 2. 3. 0. 4. 0. 0. 2. 0. 2. 4. 0. 3. 1.\n",
      " 2. 3. 4. 4. 4. 3. 0. 0. 4. 0. 1. 0. 4. 2. 2. 2. 1. 3. 1. 4. 3. 4. 0. 3.\n",
      " 4. 4. 4. 4. 3. 0. 0. 1. 4. 0. 3. 0. 1. 0. 0. 3. 2. 3. 0. 1. 2. 4. 1. 3.\n",
      " 3. 2. 0. 3. 4. 4. 2. 2. 3. 4. 3. 3. 1. 2. 4. 3. 0. 0. 0. 2. 4. 3. 1. 1.\n",
      " 1. 2. 1. 4. 0. 4. 1. 4. 4. 3. 3. 1. 2. 4. 0. 3. 4. 2. 2. 0. 4. 1. 4. 4.\n",
      " 4. 2. 2. 1. 3. 2. 1. 3. 1. 0. 0. 1. 3. 3. 3. 0. 4. 2. 1. 2. 4. 3. 4. 4.\n",
      " 4. 1. 1. 2. 3. 1. 2. 0. 0. 3. 1. 4. 2. 4. 4. 2. 2. 2. 0. 1. 3. 3. 3. 1.\n",
      " 4. 1. 1. 2. 0. 0. 2. 3. 1. 1. 2. 4. 2. 4. 4. 1. 0. 2. 0. 3. 4. 2. 4. 2.\n",
      " 0. 1. 0. 3. 1. 0. 3. 0. 2. 2. 1. 1. 3. 1. 4. 1. 2. 3. 0. 1. 0. 4. 4. 1.\n",
      " 3. 4. 3. 4. 3. 1. 3. 4. 2. 1. 4. 2. 4. 0. 3.]\n"
     ]
    }
   ],
   "source": [
    "# import all required labraries\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import os\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "\n",
    "# save and run\n",
    "\n",
    "# now define path to dataset\n",
    "path=\"asl_alphabet_train/asl_alphabet_train\"\n",
    "files=os.listdir(path)\n",
    "# list of files in path\n",
    "# sort path from A-Y\n",
    "files.sort()\n",
    "\n",
    "# print to see list\n",
    "print(files)\n",
    "\n",
    "\n",
    "# create list of image and label\n",
    "\n",
    "image_array=[]\n",
    "label_array=[]\n",
    "# loop through each file in files\n",
    "\n",
    "for i in tqdm(range(len(files))):\n",
    "\t# list of image in each folder\n",
    "\tsub_file=os.listdir(path+\"/\"+files[i])\n",
    "\t# let's check length of each folder\n",
    "\t#\tprint(len(sub_file))\n",
    "\n",
    "\t# loop through each sub folder\n",
    "\tfor j in range(len(sub_file)):\n",
    "\n",
    "\t\t# path of each image\n",
    "\t\t#Example:imagepro/A/image_name1.jpg\n",
    "\n",
    "\t\tfile_path=path+\"/\"+files[i]+\"/\"+sub_file[j]\n",
    "\t\t# read each image\n",
    "\n",
    "\t\timage=cv2.imread(file_path)\n",
    "\n",
    "\t\t# resize image by 96x96\n",
    "\t\timage=cv2.resize(image,(96,96))\n",
    "\t\t# convert BGR image to RGB image\n",
    "\t\timage=cv2.cvtColor(image,cv2.COLOR_BGR2RGB)\n",
    "\n",
    "\t\t# add this image at image_array\n",
    "\t\timage_array.append(image)\n",
    "\n",
    "\t\t# add label to label_array\n",
    "\t\t# i is number from 0 to len(files)-1\n",
    "\t\t# so we can use it as label\n",
    "\t\tlabel_array.append(i)\n",
    "\n",
    "# save and run to see if it is working or not\n",
    "# before that apply tqdm to for loop\n",
    "# it is working with no errors\n",
    "\n",
    "# convert list to array\n",
    "\n",
    "image_array=np.array(image_array)\n",
    "label_array=np.array(label_array,dtype=\"float\")\n",
    "\n",
    "# split the dataset into test and train\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "# output\t\t\t\t\t\t\t\t\t   train image   label      spliting size\n",
    "X_train,X_test,Y_train,Y_test=train_test_split(image_array,label_array,test_size=0.15)\n",
    "\n",
    "del image_array,label_array\n",
    "\n",
    "# to free memory \n",
    "import gc\n",
    "gc.collect()\n",
    "\n",
    "\n",
    "# X_train will have 85% of images \n",
    "# X_test will have 15% of images\n",
    "\n",
    "\n",
    "# Create a model\n",
    "\n",
    "from keras import layers,callbacks,utils,applications,optimizers\n",
    "from keras.models import Sequential, Model, load_model\n",
    "\n",
    "model = Sequential([\n",
    "    layers.Rescaling(1./255),\n",
    "    layers.Conv2D(16, 3, padding='same', activation='relu'),\n",
    "    layers.MaxPooling2D(),\n",
    "\n",
    "    layers.Conv2D(32, 3, padding='same', activation='relu'),\n",
    "    layers.MaxPooling2D(),\n",
    "    layers.Dropout(0.25),\n",
    "\n",
    "    layers.Conv2D(64, 3, padding='same', activation='relu'),\n",
    "    layers.MaxPooling2D(),\n",
    "    layers.Dropout(0.25),\n",
    "    \n",
    "    layers.Conv2D(128, 3, padding='same', activation='relu'),\n",
    "    layers.MaxPooling2D(),\n",
    "    layers.Dropout(0.25),\n",
    "\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(256, activation='relu'),\n",
    "    layers.Dense(len(files), activation='softmax')\n",
    "])\n",
    "\n",
    "model.build(input_shape=(None,96,96,3))\n",
    "\n",
    "# to see model summary\n",
    "model.summary()\n",
    "\n",
    "\n",
    "# save and run to see model summary \n",
    "# make sure your pc is connected to internet to download pretrained weight\n",
    "# It will take some time\n",
    "# Everything till now works\n",
    "# I am using GPU to train model so it will take 20-30 min.\n",
    "# If you train model on CPU it will take some time\n",
    "\n",
    "\n",
    "# compile model\n",
    "# you can use different optimizer and loss function to increase accuracy\n",
    "model.compile(optimizer=\"adam\",loss=\"mae\",metrics=[\"mae\"])\n",
    "\n",
    "# create a checkpoint to save best accuracy model\n",
    "ckp_path=\"trained_model/model\"\n",
    "model_checkpoint=tf.keras.callbacks.ModelCheckpoint(\n",
    "\t\t\t\t\t\t\t\t\tfilepath=ckp_path,\n",
    "\t\t\t\t\t\t\t\t\tmonitor=\"val_mae\",\n",
    "\t\t\t\t\t\t\t\t\tmode=\"auto\",\n",
    "\t\t\t\t\t\t\t\t\tsave_best_only=True,\n",
    "\t\t\t\t\t\t\t\t\tsave_weights_only=True\n",
    "\t\t\t\t\t\t\t\t\t)\n",
    "# monitor: monitor validation mae loss to save model\n",
    "# mode: Use to save model when val_mae is minimum or maximum\n",
    "# It has 3 option: \"min\",\"max\",\"auto\".\n",
    "# for us you can select either \"min\" or \"auto\"\n",
    "# When val_mae reduce model will be saved\n",
    "# save_best_only: False -> It will save all model\n",
    "# save_weights_only: Save only weight.\n",
    "\n",
    "\n",
    "# create learning rate reducer to reduce lr when accuracy does not improve\n",
    "# Correct \n",
    "reduce_lr=tf.keras.callbacks.ReduceLROnPlateau(\n",
    "\t\t\t\t\t\t\t\t\tfactor=0.9,\n",
    "\t\t\t\t\t\t\t\t\tmonitor=\"val_mae\",\n",
    "\t\t\t\t\t\t\t\t\tmode=\"auto\",\n",
    "\t\t\t\t\t\t\t\t\tcooldown=0,\n",
    "\t\t\t\t\t\t\t\t\tpatience=5,\n",
    "\t\t\t\t\t\t\t\t\tverbose=1,\n",
    "\t\t\t\t\t\t\t\t\tmin_lr=1e-6)\n",
    "\n",
    "# factor: when it is reduce next lr will be 0.9 times of current\n",
    "# next lr= 0.9* current lr\n",
    "\n",
    "# patience=X\n",
    "# reduce lr after X epoch when accuracy does not improve\n",
    "# verbose : show it after every epoch\n",
    "\n",
    "# min_lr : minimum learning rate \n",
    "\n",
    "# Start training model\n",
    "\n",
    "Epochs=5\n",
    "Batch_Size=32\n",
    "# Select batch size according to your Graphic card \n",
    "#\n",
    "#X_train,X_test,Y_train,Y_test\n",
    "with tf.device('/device:GPU:0'):\n",
    "\thistory=model.fit(\n",
    "\t\t\t\t\tX_train,\n",
    "\t\t\t\t\tY_train,\n",
    "\t\t\t\t\tvalidation_data=(X_test,Y_test),\n",
    "\t\t\t\t\tbatch_size=Batch_Size,\n",
    "\t\t\t\t\tepochs=Epochs,\n",
    "\t\t\t\t\tcallbacks=[model_checkpoint,reduce_lr]\n",
    "\t\t\t\t\t)\n",
    "# Before training you can delete image_array and label_array to increase ram memory \n",
    "\n",
    "# Some error correction\n",
    "# This code will be in the description so you can cross check everything\n",
    "# Save and run \n",
    "# Everything is working\n",
    "\n",
    "# after the training is done load best model\n",
    "\n",
    "model.load_weights(ckp_path)\n",
    "\n",
    "# convert model to tensorflow lite model\n",
    "\n",
    "converter=tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "tflite_model=converter.convert()\n",
    "\n",
    "# save model\n",
    "with open(\"model.tflite\",\"wb\") as f:\n",
    "\tf.write(tflite_model)\n",
    "\n",
    "# if you want to see prediction result on test dataset\n",
    "prediction_val=model.predict(X_test,batch_size=32)\n",
    "\n",
    "# print first 10 values\n",
    "print(prediction_val)\n",
    "# print first 10 values of Y_test\n",
    "print(Y_test)\n",
    "\n",
    "# Save and run this python file\n",
    "# Before that I will show you\n",
    "# loss: 0.4074 - mae: 0.4074 - val_loss: 0.3797 - val_mae: 0.3797\n",
    "# we have mae and val_mae:\n",
    "# mae: Is on X_train\n",
    "# val_mae: X_test\n",
    "# If val_mae is reducing that means your model is improving.\n",
    "\n",
    "# I will show you the result after the training is over\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "d2e58205",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['A_test.jpg', 'B_test.jpg', 'C_test.jpg', 'D_test.jpg', 'E_test.jpg']\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "[[0.21298537 0.21389721 0.20773737 0.18539144 0.17998867]\n",
      " [0.21251121 0.21006413 0.20668031 0.18277222 0.18797213]\n",
      " [0.21148315 0.20117682 0.2068692  0.18551487 0.19495589]\n",
      " [0.21442027 0.20672616 0.20595932 0.18170664 0.1911876 ]\n",
      " [0.21132101 0.20279136 0.20225364 0.18744986 0.19618414]]\n",
      "[0. 1. 2. 3. 4.]\n",
      "<class 'numpy.ndarray'>\n",
      "[[0.21298537 0.21389721 0.20773737 0.18539144 0.17998867]\n",
      " [0.21251121 0.21006413 0.20668031 0.18277222 0.18797213]\n",
      " [0.21148315 0.20117682 0.2068692  0.18551487 0.19495589]\n",
      " [0.21442027 0.20672616 0.20595932 0.18170664 0.1911876 ]\n",
      " [0.21132101 0.20279136 0.20225364 0.18744986 0.19618414]]\n",
      "[0.21298537 0.21389721 0.20773737 0.18539144 0.17998867]  Pred= "
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[1;32mIn [40]\u001b[0m, in \u001b[0;36m<cell line: 81>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     81\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(files)):\n\u001b[0;32m     82\u001b[0m     \n\u001b[0;32m     83\u001b[0m     \u001b[38;5;66;03m#print(prediction_val[i], \" Act=\", leter[i], \" Pred=\", end=\" \")\u001b[39;00m\n\u001b[0;32m     84\u001b[0m     \u001b[38;5;28mprint\u001b[39m(prediction_val[i], \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m Pred=\u001b[39m\u001b[38;5;124m\"\u001b[39m, end\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 86\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mprediction_val\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m>\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m0.5\u001b[39;49m \u001b[38;5;129;01mand\u001b[39;00m prediction_val[i]\u001b[38;5;241m<\u001b[39m\u001b[38;5;241m0.5\u001b[39m:\n\u001b[0;32m     87\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m= A\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     88\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m prediction_val[i]\u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m0.5\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m prediction_val[i]\u001b[38;5;241m<\u001b[39m\u001b[38;5;241m1.5\u001b[39m:\n",
      "\u001b[1;31mValueError\u001b[0m: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()"
     ]
    }
   ],
   "source": [
    "# now define path to dataset\n",
    "path=\"asl_alphabet_test/asl_alphabet_test\"\n",
    "files=os.listdir(path)\n",
    "# list of files in path\n",
    "# sort path from A-Y\n",
    "files.sort()\n",
    "\n",
    "# print to see list\n",
    "print(files)\n",
    "\n",
    "\n",
    "# create list of image and label\n",
    "\n",
    "image_array=[]\n",
    "label_array=[]\n",
    "# loop through each file in files\n",
    "\n",
    "#for i in tqdm(range(len(files))):\n",
    "\t# list of image in each folder\n",
    "\t#sub_file=os.listdir(path+\"/\"+files[i])\n",
    "\t# let's check length of each folder\n",
    "\t#\tprint(len(sub_file))\n",
    "\n",
    "i=0\n",
    "# loop through each sub folder\n",
    "for j in range(len(files)):\n",
    "\n",
    "    # path of each image\n",
    "    #Example:imagepro/A/image_name1.jpg\n",
    "\n",
    "    file_path=path+\"/\"+files[j]\n",
    "    # read each image\n",
    "\n",
    "    image=cv2.imread(file_path)\n",
    "\n",
    "    # resize image by 96x96\n",
    "    image=cv2.resize(image,(96,96))\n",
    "    # convert BGR image to RGB image\n",
    "    image=cv2.cvtColor(image,cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    # add this image at image_array\n",
    "    image_array.append(image)\n",
    "\n",
    "    # add label to label_array\n",
    "    # i is number from 0 to len(files)-1\n",
    "    # so we can use it as label\n",
    "    label_array.append(i)\n",
    "    i=i+1\n",
    "\n",
    "# save and run to see if it is working or not\n",
    "# before that apply tqdm to for loop\n",
    "# it is working with no errors\n",
    "\n",
    "# convert list to array\n",
    "\n",
    "image_array=np.array(image_array)\n",
    "label_array=np.array(label_array,dtype=\"float\")\n",
    "\n",
    "# if you want to see prediction result on test dataset\n",
    "prediction_val=model.predict(image_array,batch_size=32)\n",
    "\n",
    "# print first 10 values\n",
    "print(prediction_val)\n",
    "# print first 10 values of Y_test\n",
    "print(label_array)\n",
    "\n",
    "import string\n",
    "leter=()\n",
    "leter=list(string.ascii_uppercase)\n",
    "\n",
    "print(type(prediction_val[1]))\n",
    "\n",
    "# for i in range(len(prediction_val)):\n",
    "#     prediction_val[i][1]=prediction_val[i][np.argmax(prediction_val[i])]\n",
    "\n",
    "# prediction_val=100*np.array(prediction_val)\n",
    "\n",
    "print(prediction_val)\n",
    "\n",
    "j=0\n",
    "for i in range(len(files)):\n",
    "    \n",
    "    #print(prediction_val[i], \" Act=\", leter[i], \" Pred=\", end=\" \")\n",
    "    print(prediction_val[i], \" Pred=\", end=\" \")\n",
    "    \n",
    "    if prediction_val[i]>=-0.5 and prediction_val[i]<0.5:\n",
    "        print(\"= A\")\n",
    "    elif prediction_val[i]>=-0.5 and prediction_val[i]<1.5:\n",
    "        print(\"= B\")\n",
    "    elif prediction_val[i]>=-1.5 and prediction_val[i]<2.5:\n",
    "        print(\"= C\")\n",
    "    elif prediction_val[i]>=-2.5 and prediction_val[i]<3.5:\n",
    "        print(\"= D\")\n",
    "    elif prediction_val[i]>=-3.5 and prediction_val[i]<4.5:\n",
    "        print(\"= E\")\n",
    "    elif prediction_val[i]>=-4.5 and prediction_val[i]<5.5:\n",
    "        print(\"= F\")\n",
    "    elif prediction_val[i]>=-5.5 and prediction_val[i]<6.5:\n",
    "        print(\"= G\")\n",
    "    elif prediction_val[i]>=-6.5 and prediction_val[i]<7.5:\n",
    "        print(\"= H\")\n",
    "    elif prediction_val[i]>=-7.5 and prediction_val[i]<8.5:\n",
    "        print(\"= I\")\n",
    "    elif prediction_val[i]>=-8.5 and prediction_val[i]<9.5:\n",
    "        print(\"= J\")\n",
    "        \n",
    "    elif prediction_val[i]>=-9.5 and prediction_val[i]<10.5:\n",
    "        print(\"= K\")\n",
    "    elif prediction_val[i]>=-10.5 and prediction_val[i]<11.5:\n",
    "        print(\"= L\")\n",
    "    elif prediction_val[i]>=-11.5 and prediction_val[i]<12.5:\n",
    "        print(\"= M\")\n",
    "    elif prediction_val[i]>=-12.5 and prediction_val[i]<13.5:\n",
    "        print(\"= N\")\n",
    "    elif prediction_val[i]>=-13.5 and prediction_val[i]<14.5:\n",
    "        print(\"= O\")\n",
    "    elif prediction_val[i]>=-14.5 and prediction_val[i]<15.5:\n",
    "        print(\"= P\")\n",
    "    elif prediction_val[i]>=-15.5 and prediction_val[i]<16.5:\n",
    "        print(\"= Q\")\n",
    "    elif prediction_val[i]>=-16.5 and prediction_val[i]<17.5:\n",
    "        print(\"= R\")\n",
    "    elif prediction_val[i]>=-17.5 and prediction_val[i]<18.5:\n",
    "        print(\"= S\")\n",
    "    elif prediction_val[i]>=-18.5 and prediction_val[i]<19.5:\n",
    "        print(\"= T\")\n",
    "    \n",
    "    elif prediction_val[i]>=-19.5 and prediction_val[i]<20.5:\n",
    "        print(\"= U\")\n",
    "    elif prediction_val[i]>=-20.5 and prediction_val[i]<21.5:\n",
    "        print(\"= V\")\n",
    "    elif prediction_val[i]>=-21.5 and prediction_val[i]<22.5:\n",
    "        print(\"= W\")\n",
    "    elif prediction_val[i]>=-22.5 and prediction_val[i]<23.5:\n",
    "        print(\"= X\")\n",
    "    elif prediction_val[i]>=-23.5 and prediction_val[i]<24.5:\n",
    "        print(\"= Y\")\n",
    "    elif prediction_val[i]>=-24.5 and prediction_val[i]<25.5:\n",
    "        print(\"= Z\")\n",
    "    elif prediction_val[i]>=-25.5 and prediction_val[i]<26.5:\n",
    "        print(\"= DEL\")\n",
    "    elif prediction_val[i]>=-26.5 and prediction_val[i]<27.5:\n",
    "        print(\"= NOTHING\")\n",
    "    elif prediction_val[i]>=-27.5 and prediction_val[i]<28.5:\n",
    "        print(\"= SPACE\")\n",
    "    else:\n",
    "        print(\"= Dont Know!\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
