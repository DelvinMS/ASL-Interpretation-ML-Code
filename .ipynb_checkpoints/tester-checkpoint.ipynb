{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3a531016",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z', 'del', 'nothing', 'space']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [03:23<00:00,  7.01s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " efficientnetb0 (Functional)  (None, 3, 3, 1280)       4049571   \n",
      "                                                                 \n",
      " global_average_pooling2d (G  (None, 1280)             0         \n",
      " lobalAveragePooling2D)                                          \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 1280)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1)                 1281      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4,050,852\n",
      "Trainable params: 4,008,829\n",
      "Non-trainable params: 42,023\n",
      "_________________________________________________________________\n",
      "Epoch 1/5\n",
      "1156/1156 [==============================] - 803s 687ms/step - loss: 1.8697 - mae: 1.8697 - val_loss: 0.9010 - val_mae: 0.9010 - lr: 0.0010\n",
      "Epoch 2/5\n",
      "1156/1156 [==============================] - 800s 692ms/step - loss: 0.7100 - mae: 0.7100 - val_loss: 0.3577 - val_mae: 0.3577 - lr: 0.0010\n",
      "Epoch 3/5\n",
      "1156/1156 [==============================] - 784s 678ms/step - loss: 0.5238 - mae: 0.5238 - val_loss: 0.7902 - val_mae: 0.7902 - lr: 0.0010\n",
      "Epoch 4/5\n",
      "1156/1156 [==============================] - 786s 680ms/step - loss: 0.5919 - mae: 0.5919 - val_loss: 0.1962 - val_mae: 0.1962 - lr: 0.0010\n",
      "Epoch 5/5\n",
      "1156/1156 [==============================] - 784s 678ms/step - loss: 0.4546 - mae: 0.4546 - val_loss: 0.2396 - val_mae: 0.2396 - lr: 0.0010\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 81). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\DELVIN\\AppData\\Local\\Temp\\tmphsp_7tcn\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\DELVIN\\AppData\\Local\\Temp\\tmphsp_7tcn\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "204/204 [==============================] - 35s 164ms/step\n",
      "[[ 4.0252466]\n",
      " [ 5.1253858]\n",
      " [24.169882 ]\n",
      " [17.234184 ]\n",
      " [11.440095 ]\n",
      " [20.2275   ]\n",
      " [20.231606 ]\n",
      " [ 7.921851 ]\n",
      " [21.046053 ]\n",
      " [16.1599   ]]\n",
      "[ 4.  5. 24. 17. 11. 20. 20.  8. 20. 16.]\n"
     ]
    }
   ],
   "source": [
    "# import all required labraries\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import os\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "\n",
    "# save and run\n",
    "\n",
    "# now define path to dataset\n",
    "path=\"asl_alphabet_train/asl_alphabet_train\"\n",
    "files=os.listdir(path)\n",
    "# list of files in path\n",
    "# sort path from A-Y\n",
    "files.sort()\n",
    "\n",
    "# print to see list\n",
    "print(files)\n",
    "\n",
    "\n",
    "# create list of image and label\n",
    "\n",
    "image_array=[]\n",
    "label_array=[]\n",
    "# loop through each file in files\n",
    "\n",
    "for i in tqdm(range(len(files))):\n",
    "\t# list of image in each folder\n",
    "\tsub_file=os.listdir(path+\"/\"+files[i])\n",
    "\t# let's check length of each folder\n",
    "\t#\tprint(len(sub_file))\n",
    "\n",
    "\t# loop through each sub folder\n",
    "\tfor j in range(len(sub_file)):\n",
    "\n",
    "\t\t# path of each image\n",
    "\t\t#Example:imagepro/A/image_name1.jpg\n",
    "\n",
    "\t\tfile_path=path+\"/\"+files[i]+\"/\"+sub_file[j]\n",
    "\t\t# read each image\n",
    "\n",
    "\t\timage=cv2.imread(file_path)\n",
    "\n",
    "\t\t# resize image by 96x96\n",
    "\t\timage=cv2.resize(image,(96,96))\n",
    "\t\t# convert BGR image to RGB image\n",
    "\t\timage=cv2.cvtColor(image,cv2.COLOR_BGR2RGB)\n",
    "\n",
    "\t\t# add this image at image_array\n",
    "\t\timage_array.append(image)\n",
    "\n",
    "\t\t# add label to label_array\n",
    "\t\t# i is number from 0 to len(files)-1\n",
    "\t\t# so we can use it as label\n",
    "\t\tlabel_array.append(i)\n",
    "\n",
    "# save and run to see if it is working or not\n",
    "# before that apply tqdm to for loop\n",
    "# it is working with no errors\n",
    "\n",
    "# convert list to array\n",
    "\n",
    "image_array=np.array(image_array)\n",
    "label_array=np.array(label_array,dtype=\"float\")\n",
    "\n",
    "# split the dataset into test and train\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "# output\t\t\t\t\t\t\t\t\t   train image   label      spliting size\n",
    "X_train,X_test,Y_train,Y_test=train_test_split(image_array,label_array,test_size=0.15)\n",
    "\n",
    "del image_array,label_array\n",
    "\n",
    "# to free memory \n",
    "import gc\n",
    "gc.collect()\n",
    "\n",
    "\n",
    "# X_train will have 85% of images \n",
    "# X_test will have 15% of images\n",
    "\n",
    "\n",
    "# Create a model\n",
    "\n",
    "from keras import layers,callbacks,utils,applications,optimizers\n",
    "from keras.models import Sequential, Model, load_model\n",
    "\n",
    "model=Sequential()\n",
    "# add pretrained models to Sequential model\n",
    "# I will use EfficientNetB0 pretrained model. You can try different model.\n",
    "pretrained_model=tf.keras.applications.EfficientNetB0(input_shape=(96,96,3),include_top=False)\n",
    "model.add(pretrained_model)\n",
    "\n",
    "# add Pooling to model\n",
    "model.add(layers.GlobalAveragePooling2D())\n",
    "\n",
    "# add dropout to model\n",
    "# We add dropout to increase accuracy by reduce overfitting\n",
    "model.add(layers.Dropout(0.3))\n",
    "# finally we will addd dense layer as an output\n",
    "model.add(layers.Dense(1))\n",
    "# For some tensorflow version we required to build model\n",
    "model.build(input_shape=(None,96,96,3))\n",
    "\n",
    "\n",
    "# to see model summary\n",
    "model.summary()\n",
    "\n",
    "\n",
    "# save and run to see model summary \n",
    "# make sure your pc is connected to internet to download pretrained weight\n",
    "# It will take some time\n",
    "# Everything till now works\n",
    "# I am using GPU to train model so it will take 20-30 min.\n",
    "# If you train model on CPU it will take some time\n",
    "\n",
    "\n",
    "# compile model\n",
    "# you can use different optimizer and loss function to increase accuracy\n",
    "model.compile(optimizer=\"adam\",loss=\"mae\",metrics=[\"mae\"])\n",
    "\n",
    "# create a checkpoint to save best accuracy model\n",
    "ckp_path=\"trained_model/model\"\n",
    "model_checkpoint=tf.keras.callbacks.ModelCheckpoint(\n",
    "\t\t\t\t\t\t\t\t\tfilepath=ckp_path,\n",
    "\t\t\t\t\t\t\t\t\tmonitor=\"val_mae\",\n",
    "\t\t\t\t\t\t\t\t\tmode=\"auto\",\n",
    "\t\t\t\t\t\t\t\t\tsave_best_only=True,\n",
    "\t\t\t\t\t\t\t\t\tsave_weights_only=True\n",
    "\t\t\t\t\t\t\t\t\t)\n",
    "# monitor: monitor validation mae loss to save model\n",
    "# mode: Use to save model when val_mae is minimum or maximum\n",
    "# It has 3 option: \"min\",\"max\",\"auto\".\n",
    "# for us you can select either \"min\" or \"auto\"\n",
    "# When val_mae reduce model will be saved\n",
    "# save_best_only: False -> It will save all model\n",
    "# save_weights_only: Save only weight.\n",
    "\n",
    "\n",
    "# create learning rate reducer to reduce lr when accuracy does not improve\n",
    "# Correct \n",
    "reduce_lr=tf.keras.callbacks.ReduceLROnPlateau(\n",
    "\t\t\t\t\t\t\t\t\tfactor=0.9,\n",
    "\t\t\t\t\t\t\t\t\tmonitor=\"val_mae\",\n",
    "\t\t\t\t\t\t\t\t\tmode=\"auto\",\n",
    "\t\t\t\t\t\t\t\t\tcooldown=0,\n",
    "\t\t\t\t\t\t\t\t\tpatience=5,\n",
    "\t\t\t\t\t\t\t\t\tverbose=1,\n",
    "\t\t\t\t\t\t\t\t\tmin_lr=1e-6)\n",
    "\n",
    "# factor: when it is reduce next lr will be 0.9 times of current\n",
    "# next lr= 0.9* current lr\n",
    "\n",
    "# patience=X\n",
    "# reduce lr after X epoch when accuracy does not improve\n",
    "# verbose : show it after every epoch\n",
    "\n",
    "# min_lr : minimum learning rate \n",
    "\n",
    "# Start training model\n",
    "\n",
    "Epochs=5\n",
    "Batch_Size=32\n",
    "# Select batch size according to your Graphic card \n",
    "#\n",
    "#X_train,X_test,Y_train,Y_test\n",
    "with tf.device('/device:GPU:0'):\n",
    "\thistory=model.fit(\n",
    "\t\t\t\t\tX_train,\n",
    "\t\t\t\t\tY_train,\n",
    "\t\t\t\t\tvalidation_data=(X_test,Y_test),\n",
    "\t\t\t\t\tbatch_size=Batch_Size,\n",
    "\t\t\t\t\tepochs=Epochs,\n",
    "\t\t\t\t\tcallbacks=[model_checkpoint,reduce_lr]\n",
    "\t\t\t\t\t)\n",
    "# Before training you can delete image_array and label_array to increase ram memory \n",
    "\n",
    "# Some error correction\n",
    "# This code will be in the description so you can cross check everything\n",
    "# Save and run \n",
    "# Everything is working\n",
    "\n",
    "# after the training is done load best model\n",
    "\n",
    "model.load_weights(ckp_path)\n",
    "\n",
    "# convert model to tensorflow lite model\n",
    "\n",
    "converter=tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "tflite_model=converter.convert()\n",
    "\n",
    "# save model\n",
    "with open(\"model.tflite\",\"wb\") as f:\n",
    "\tf.write(tflite_model)\n",
    "\n",
    "# if you want to see prediction result on test dataset\n",
    "prediction_val=model.predict(X_test,batch_size=32)\n",
    "\n",
    "# print first 10 values\n",
    "print(prediction_val)\n",
    "# print first 10 values of Y_test\n",
    "print(Y_test)\n",
    "\n",
    "# Save and run this python file\n",
    "# Before that I will show you\n",
    "# loss: 0.4074 - mae: 0.4074 - val_loss: 0.3797 - val_mae: 0.3797\n",
    "# we have mae and val_mae:\n",
    "# mae: Is on X_train\n",
    "# val_mae: X_test\n",
    "# If val_mae is reducing that means your model is improving.\n",
    "\n",
    "# I will show you the result after the training is over\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "d2e58205",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['WhatsApp Image 2022-07-17 at 1.47.42 PM.jpeg', 'WhatsApp Image 2022-07-17 at 1.47.43 PM (1).jpeg', 'WhatsApp Image 2022-07-17 at 1.47.43 PM (2).jpeg', 'WhatsApp Image 2022-07-17 at 1.47.43 PM.jpeg']\n",
      "1/1 [==============================] - 0s 55ms/step\n",
      "[[ 2.5951102]\n",
      " [15.089398 ]\n",
      " [12.51762  ]\n",
      " [23.858257 ]]\n",
      "[0. 1. 2. 3.]\n",
      "['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z']\n",
      "[2.5951102]  Pred= = D\n",
      "[15.089398]  Pred= = P\n",
      "[12.51762]  Pred= = N\n",
      "[23.858257]  Pred= = Y\n"
     ]
    }
   ],
   "source": [
    "# now define path to dataset\n",
    "path=\"DownloadedSamples\"\n",
    "files=os.listdir(path)\n",
    "# list of files in path\n",
    "# sort path from A-Y\n",
    "files.sort()\n",
    "\n",
    "# print to see list\n",
    "print(files)\n",
    "\n",
    "\n",
    "# create list of image and label\n",
    "\n",
    "image_array=[]\n",
    "label_array=[]\n",
    "# loop through each file in files\n",
    "\n",
    "#for i in tqdm(range(len(files))):\n",
    "\t# list of image in each folder\n",
    "\t#sub_file=os.listdir(path+\"/\"+files[i])\n",
    "\t# let's check length of each folder\n",
    "\t#\tprint(len(sub_file))\n",
    "\n",
    "i=0\n",
    "# loop through each sub folder\n",
    "for j in range(len(files)):\n",
    "\n",
    "    # path of each image\n",
    "    #Example:imagepro/A/image_name1.jpg\n",
    "\n",
    "    file_path=path+\"/\"+files[j]\n",
    "    # read each image\n",
    "\n",
    "    image=cv2.imread(file_path)\n",
    "\n",
    "    # resize image by 96x96\n",
    "    image=cv2.resize(image,(96,96))\n",
    "    # convert BGR image to RGB image\n",
    "    image=cv2.cvtColor(image,cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    # add this image at image_array\n",
    "    image_array.append(image)\n",
    "\n",
    "    # add label to label_array\n",
    "    # i is number from 0 to len(files)-1\n",
    "    # so we can use it as label\n",
    "    label_array.append(i)\n",
    "    i=i+1\n",
    "\n",
    "# save and run to see if it is working or not\n",
    "# before that apply tqdm to for loop\n",
    "# it is working with no errors\n",
    "\n",
    "# convert list to array\n",
    "\n",
    "image_array=np.array(image_array)\n",
    "label_array=np.array(label_array,dtype=\"float\")\n",
    "\n",
    "# if you want to see prediction result on test dataset\n",
    "prediction_val=model.predict(image_array,batch_size=32)\n",
    "\n",
    "# print first 10 values\n",
    "print(prediction_val)\n",
    "# print first 10 values of Y_test\n",
    "print(label_array)\n",
    "\n",
    "import string\n",
    "leter=()\n",
    "leter=list(string.ascii_uppercase)\n",
    "print(leter)\n",
    "\n",
    "j=0\n",
    "for i in range(len(files)):\n",
    "    \n",
    "    #print(prediction_val[i], \" Act=\", leter[i], \" Pred=\", end=\" \")\n",
    "    print(prediction_val[i], \" Pred=\", end=\" \")\n",
    "    \n",
    "    if prediction_val[i]>=-0.5 and prediction_val[i]<0.5:\n",
    "        print(\"= A\")\n",
    "    elif prediction_val[i]>=-0.5 and prediction_val[i]<1.5:\n",
    "        print(\"= B\")\n",
    "    elif prediction_val[i]>=-1.5 and prediction_val[i]<2.5:\n",
    "        print(\"= C\")\n",
    "    elif prediction_val[i]>=-2.5 and prediction_val[i]<3.5:\n",
    "        print(\"= D\")\n",
    "    elif prediction_val[i]>=-3.5 and prediction_val[i]<4.5:\n",
    "        print(\"= E\")\n",
    "    elif prediction_val[i]>=-4.5 and prediction_val[i]<5.5:\n",
    "        print(\"= F\")\n",
    "    elif prediction_val[i]>=-5.5 and prediction_val[i]<6.5:\n",
    "        print(\"= G\")\n",
    "    elif prediction_val[i]>=-6.5 and prediction_val[i]<7.5:\n",
    "        print(\"= H\")\n",
    "    elif prediction_val[i]>=-7.5 and prediction_val[i]<8.5:\n",
    "        print(\"= I\")\n",
    "    elif prediction_val[i]>=-8.5 and prediction_val[i]<9.5:\n",
    "        print(\"= J\")\n",
    "        \n",
    "    elif prediction_val[i]>=-9.5 and prediction_val[i]<10.5:\n",
    "        print(\"= K\")\n",
    "    elif prediction_val[i]>=-10.5 and prediction_val[i]<11.5:\n",
    "        print(\"= L\")\n",
    "    elif prediction_val[i]>=-11.5 and prediction_val[i]<12.5:\n",
    "        print(\"= M\")\n",
    "    elif prediction_val[i]>=-12.5 and prediction_val[i]<13.5:\n",
    "        print(\"= N\")\n",
    "    elif prediction_val[i]>=-13.5 and prediction_val[i]<14.5:\n",
    "        print(\"= O\")\n",
    "    elif prediction_val[i]>=-14.5 and prediction_val[i]<15.5:\n",
    "        print(\"= P\")\n",
    "    elif prediction_val[i]>=-15.5 and prediction_val[i]<16.5:\n",
    "        print(\"= Q\")\n",
    "    elif prediction_val[i]>=-16.5 and prediction_val[i]<17.5:\n",
    "        print(\"= R\")\n",
    "    elif prediction_val[i]>=-17.5 and prediction_val[i]<18.5:\n",
    "        print(\"= S\")\n",
    "    elif prediction_val[i]>=-18.5 and prediction_val[i]<19.5:\n",
    "        print(\"= T\")\n",
    "    \n",
    "    elif prediction_val[i]>=-19.5 and prediction_val[i]<20.5:\n",
    "        print(\"= U\")\n",
    "    elif prediction_val[i]>=-20.5 and prediction_val[i]<21.5:\n",
    "        print(\"= V\")\n",
    "    elif prediction_val[i]>=-21.5 and prediction_val[i]<22.5:\n",
    "        print(\"= W\")\n",
    "    elif prediction_val[i]>=-22.5 and prediction_val[i]<23.5:\n",
    "        print(\"= X\")\n",
    "    elif prediction_val[i]>=-23.5 and prediction_val[i]<24.5:\n",
    "        print(\"= Y\")\n",
    "    elif prediction_val[i]>=-24.5 and prediction_val[i]<25.5:\n",
    "        print(\"= Z\")\n",
    "    elif prediction_val[i]>=-25.5 and prediction_val[i]<26.5:\n",
    "        print(\"= DEL\")\n",
    "    elif prediction_val[i]>=-26.5 and prediction_val[i]<27.5:\n",
    "        print(\"= NOTHING\")\n",
    "    elif prediction_val[i]>=-27.5 and prediction_val[i]<28.5:\n",
    "        print(\"= SPACE\")\n",
    "    else:\n",
    "        print(\"= Dont Know!\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
